Wikipedia dataset containing cleaned articles of all languages as of 2023-11-01.

The dataset is built from the Wikipedia dumps (https://dumps.wikimedia.org/) with one subset per language, each containing a single train split.

https://huggingface.co/datasets/wikimedia/wikipedia

Languages : ff, kab, zgh, wol, bam